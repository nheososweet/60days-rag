# üìò Gi·∫£i th√≠ch Chi ti·∫øt - Qwen3 Integration

## üéØ T·ªïng quan ki·∫øn tr√∫c

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       USER/CLIENT                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              FastAPI Application (Port 8000)                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  API Layer: app/api/qwen.py                        ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  - POST /qwen/chat (non-streaming)                 ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  - POST /qwen/chat/stream (streaming SSE)          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  - GET /qwen/health                                ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  - GET /qwen/info                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
                            ‚Üì
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Service Layer: app/services/qwen_service.py       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  - generate_response() ‚Üí Non-streaming             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  - generate_stream_response() ‚Üí Streaming          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  - check_health() ‚Üí Health check                   ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
                            ‚Üì
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  HTTP Client (httpx AsyncClient)                   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  - G·ªçi vLLM API                                    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  - Handle streaming/non-streaming                  ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              vLLM Server (Port 8000)                        ‚îÇ
‚îÇ  - OpenAI-compatible API                                    ‚îÇ
‚îÇ  - Endpoint: /v1/chat/completions                          ‚îÇ
‚îÇ  - Qwen3-0.6B model loaded in memory                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÇ Files Created - Chi ti·∫øt t·ª´ng file

### 1. `app/core/config.py` (Updated)

**Vai tr√≤:** Qu·∫£n l√Ω configuration

**Th√™m m·ªõi:**

```python
QWEN_BASE_URL: str = "http://localhost:8000"  # vLLM server URL
QWEN_MODEL: str = "Qwen/Qwen3-0.6B"          # Model name
QWEN_TIMEOUT: int = 120                       # Request timeout
```

**Gi·∫£i th√≠ch:**

- `QWEN_BASE_URL`: ƒê·ªãa ch·ªâ c·ªßa vLLM server (KH√ÅC v·ªõi FastAPI port!)
- `QWEN_MODEL`: T√™n model ƒë·ªÉ display v√† verify
- `QWEN_TIMEOUT`: Timeout cho HTTP requests (120s v√¨ inference c√≥ th·ªÉ l√¢u)

**Environment Variables (.env):**

```env
QWEN_BASE_URL=http://localhost:8000
QWEN_MODEL=Qwen/Qwen3-0.6B
QWEN_TIMEOUT=120
```

---

### 2. `app/services/qwen_service.py` (New)

**Vai tr√≤:** Business logic layer - Giao ti·∫øp v·ªõi vLLM

#### **Class: QwenService**

##### **Method: `__init__()`**

```python
def __init__(self):
    self.base_url = settings.QWEN_BASE_URL
    self.model_name = settings.QWEN_MODEL
    self.client = httpx.AsyncClient(timeout=settings.QWEN_TIMEOUT)
```

**Gi·∫£i th√≠ch:**

- Load config t·ª´ settings
- T·∫°o async HTTP client v·ªõi timeout
- Client n√†y s·∫Ω reuse connections (efficient!)

##### **Method: `generate_response()` - NON-STREAMING**

**Flow:**

```
1. Chu·∫©n b·ªã messages (system + user)
   ‚Üì
2. T·∫°o payload theo OpenAI format
   ‚Üì
3. POST t·ªõi /v1/chat/completions v·ªõi stream=False
   ‚Üì
4. Nh·∫≠n full response
   ‚Üì
5. Parse v√† return
```

**Request Format:**

```json
{
  "model": "Qwen/Qwen3-0.6B",
  "messages": [
    { "role": "system", "content": "You are..." },
    { "role": "user", "content": "Hello" }
  ],
  "temperature": 0.7,
  "max_tokens": 2048,
  "stream": false
}
```

**Response Format:**

```json
{
  "choices": [
    {
      "message": {
        "content": "Response text here..."
      }
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 50,
    "total_tokens": 60
  }
}
```

**Tr·∫£ v·ªÅ:**

```python
{
    "response": "Text response",
    "conversation_id": "qwen_conv_abc123",
    "model": "Qwen/Qwen3-0.6B",
    "usage": {...}
}
```

##### **Method: `generate_stream_response()` - STREAMING**

**Flow:**

```
1. Chu·∫©n b·ªã messages
   ‚Üì
2. POST v·ªõi stream=True
   ‚Üì
3. Nh·∫≠n SSE stream
   ‚Üì
4. Parse t·ª´ng line
   ‚Üì
5. Yield chunks
   ‚Üì
6. Done signal
```

**SSE Format t·ª´ vLLM:**

```
data: {"choices": [{"delta": {"content": "Hello"}}]}

data: {"choices": [{"delta": {"content": " world"}}]}

data: [DONE]
```

**Yield Format cho API:**

```python
{
    "chunk": "Hello",
    "done": False,
    "conversation_id": "qwen_conv_abc123"
}
# ... more chunks ...
{
    "chunk": "",
    "done": True,
    "conversation_id": "qwen_conv_abc123"
}
```

**T·∫°i sao d√πng AsyncIterator?**

```python
async def generate_stream_response(...) -> AsyncIterator[Dict]:
    async for chunk in ...:
        yield chunk
```

- `AsyncIterator` cho ph√©p yield t·ª´ng ph·∫ßn data
- Kh√¥ng c·∫ßn load h·∫øt response v√†o memory
- Client c√≥ th·ªÉ nh·∫≠n data ngay l·∫≠p t·ª©c
- Efficient v√† scalable!

##### **Method: `check_health()`**

```python
async def check_health(self) -> bool:
    try:
        response = await self.client.get(f"{base_url}/v1/models", timeout=5.0)
        return response.status_code == 200
    except:
        return False
```

**Gi·∫£i th√≠ch:**

- G·ªçi `/v1/models` endpoint c·ªßa vLLM
- Timeout ng·∫Øn (5s) v√¨ ch·ªâ l√† health check
- Return True/False thay v√¨ raise exception

---

### 3. `app/api/qwen.py` (New)

**Vai tr√≤:** API endpoints - Interface v·ªõi client

#### **Router Setup:**

```python
router = APIRouter(prefix="/qwen", tags=["Qwen Chat"])
```

- `prefix="/qwen"`: T·∫•t c·∫£ routes b·∫Øt ƒë·∫ßu v·ªõi `/qwen`
- `tags=["Qwen Chat"]`: Nh√≥m trong API docs

#### **Endpoint: `POST /qwen/chat`**

**Request ‚Üí Service ‚Üí Response:**

```
ChatRequest (Pydantic)
    ‚Üì
Validate fields
    ‚Üì
qwen_service.generate_response()
    ‚Üì
ChatResponse (Pydantic)
    ‚Üì
JSON response to client
```

**Error Handling:**

```python
try:
    result = await qwen_service.generate_response(...)
    return ChatResponse(**result)
except Exception as e:
    raise HTTPException(status_code=500, detail=str(e))
```

**Gi·∫£i th√≠ch:**

- Catch t·∫•t c·∫£ exceptions
- Convert th√†nh HTTP error (500)
- Client nh·∫≠n response r√µ r√†ng thay v√¨ connection drop

#### **Endpoint: `POST /qwen/chat/stream`**

**Streaming Flow:**

```
Client request
    ‚Üì
Create async generator (event_generator)
    ‚Üì
Generator calls qwen_service.generate_stream_response()
    ‚Üì
For each chunk:
    - Convert to JSON
    - Format as SSE: "data: {json}\n\n"
    - Yield to client
    ‚Üì
StreamingResponse sends chunks to client
```

**SSE Protocol:**

```
HTTP/1.1 200 OK
Content-Type: text/event-stream
Cache-Control: no-cache
Connection: keep-alive

data: {"chunk": "Hello", "done": false}

data: {"chunk": " world", "done": false}

data: {"chunk": "", "done": true}
```

**T·∫°i sao d√πng async generator?**

```python
async def event_generator():
    async for chunk in qwen_service.generate_stream_response(...):
        yield f"data: {json.dumps(chunk)}\n\n"
```

- Generator t·∫°o data on-demand
- Kh√¥ng block thread
- Memory efficient
- Perfect cho streaming!

#### **Endpoint: `GET /qwen/health`**

**Simple check:**

```python
is_healthy = await qwen_service.check_health()
if is_healthy:
    return {"status": "healthy", ...}
else:
    raise HTTPException(status_code=503, detail="...")
```

**HTTP Status Codes:**

- `200 OK`: Service healthy
- `503 Service Unavailable`: vLLM kh√¥ng accessible

---

### 4. `main.py` (Updated)

**Import Qwen router:**

```python
from app.api.qwen import router as qwen_router
```

**Include router:**

```python
app.include_router(qwen_router)
```

**Order matters:**

```python
app.include_router(health_router)  # Root v√† health
app.include_router(chat_router)    # Gemini (/chat)
app.include_router(qwen_router)    # Qwen (/qwen)
app.include_router(rag_router)     # RAG (/rag)
```

**Gi·∫£i th√≠ch:**

- Health check ƒë·∫ßu ti√™n (most basic)
- Gemini v√† Qwen t√°ch bi·ªát
- RAG cu·ªëi c√πng (s·∫Ω d√πng c·∫£ Gemini v√† Qwen)

---

### 5. `test_qwen.py` (New)

**Test Suite Structure:**

```python
1. test_health_check()           # Basic connectivity
2. test_model_info()             # Static info
3. test_non_streaming_chat()     # Core functionality
4. test_streaming_chat()         # Streaming functionality
5. test_with_system_prompt()     # Advanced features
```

**T·∫°i sao test theo th·ª© t·ª± n√†y?**

1. Health check tr∆∞·ªõc ‚Üí Fail fast n·∫øu server kh√¥ng ch·∫°y
2. Model info ‚Üí Static endpoint, kh√¥ng c·∫ßn vLLM
3. Non-streaming ‚Üí ƒê∆°n gi·∫£n nh·∫•t
4. Streaming ‚Üí Ph·ª©c t·∫°p h∆°n
5. System prompts ‚Üí Advanced use case

---

## üîÑ Data Flow Examples

### Example 1: Non-Streaming Chat

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ POST /qwen/chat
     ‚îÇ {"message": "Hello"}
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ qwen.py         ‚îÇ
‚îÇ @router.post    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ await qwen_service.generate_response(...)
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ qwen_service.py  ‚îÇ
‚îÇ generate_response‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ POST http://localhost:8000/v1/chat/completions
     ‚îÇ {"model": "...", "messages": [...], "stream": false}
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ vLLM Server ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ {"choices": [{"message": {"content": "Hi!"}}]}
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ qwen_service.py  ‚îÇ
‚îÇ Parse response   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ {"response": "Hi!", "conversation_id": "..."}
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ qwen.py         ‚îÇ
‚îÇ ChatResponse    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ JSON
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client  ‚îÇ Receives: {"response": "Hi!", ...}
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Example 2: Streaming Chat

```
Client                  API                 Service              vLLM
  ‚îÇ                      ‚îÇ                     ‚îÇ                   ‚îÇ
  ‚îÇ POST /qwen/stream    ‚îÇ                     ‚îÇ                   ‚îÇ
  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                     ‚îÇ                   ‚îÇ
  ‚îÇ                      ‚îÇ call generator      ‚îÇ                   ‚îÇ
  ‚îÇ                      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                   ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ POST stream=true  ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ                   ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ SSE chunk 1       ‚îÇ
  ‚îÇ                      ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                   ‚îÇ
  ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ "data: {...}\n\n"  ‚îÇ                   ‚îÇ
  ‚îÇ Chunk 1              ‚îÇ                     ‚îÇ                   ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ SSE chunk 2       ‚îÇ
  ‚îÇ                      ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                   ‚îÇ
  ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ "data: {...}\n\n"  ‚îÇ                   ‚îÇ
  ‚îÇ Chunk 2              ‚îÇ                     ‚îÇ                   ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ                   ‚îÇ
  ‚îÇ ...                  ‚îÇ ...                 ‚îÇ ...               ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ                   ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
  ‚îÇ                      ‚îÇ                     ‚îÇ [DONE]            ‚îÇ
  ‚îÇ                      ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                   ‚îÇ
  ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ "data: {done:true}"‚îÇ                   ‚îÇ
  ‚îÇ Done!                ‚îÇ                     ‚îÇ                   ‚îÇ
```

---

## üéì Key Concepts Explained

### 1. **Async/Await**

```python
async def generate_response(...):  # async function
    response = await self.client.post(...)  # await = ch·ªù kh√¥ng block
    return result
```

**T·∫°i sao d√πng async?**

- Kh√¥ng block thread khi ch·ªù I/O
- C√≥ th·ªÉ handle nhi·ªÅu requests c√πng l√∫c
- Better performance v√† scalability

### 2. **AsyncIterator v√† Yield**

```python
async def generate_stream_response(...) -> AsyncIterator[Dict]:
    async for chunk in stream:
        yield {"chunk": chunk}  # Yield = tr·∫£ v·ªÅ t·ª´ng ph·∫ßn
```

**Iterator vs Regular Function:**

```python
# Regular function - return all at once
def get_numbers():
    return [1, 2, 3, 4, 5]

# Iterator - yield one by one
def generate_numbers():
    for i in range(1, 6):
        yield i
```

### 3. **Server-Sent Events (SSE)**

**Format:**

```
data: <json>\n\n
```

**Example:**

```
data: {"chunk": "Hello"}

data: {"chunk": " world"}

data: [DONE]
```

**Client consumption:**

```javascript
// JavaScript
const eventSource = new EventSource("/qwen/chat/stream");
eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(data.chunk);
};
```

```python
# Python
response = requests.post(..., stream=True)
for line in response.iter_lines():
    if line.startswith(b'data: '):
        data = json.loads(line[6:])
        print(data['chunk'], end='')
```

### 4. **Context Manager (async with)**

```python
async with self.client.stream(...) as response:
    async for line in response.aiter_lines():
        # Process line
```

**Gi·∫£i th√≠ch:**

- `async with` ƒë·∫£m b·∫£o connection ƒë∆∞·ª£c close sau khi done
- T·ª± ƒë·ªông cleanup resources
- Exception safe

### 5. **Error Handling Layers**

```
Layer 1: Service Layer
‚îú‚îÄ Try/catch HTTP errors
‚îî‚îÄ Convert to Python exceptions

Layer 2: API Layer
‚îú‚îÄ Try/catch service exceptions
‚îî‚îÄ Convert to HTTPException

Layer 3: FastAPI
‚îú‚îÄ Catch HTTPException
‚îî‚îÄ Return JSON error response

Layer 4: Global Handler
‚îú‚îÄ Catch unhandled exceptions
‚îî‚îÄ Return 500 error
```

---

## üí° Best Practices Applied

### 1. **Separation of Concerns**

```
API Layer (qwen.py)
‚îú‚îÄ Handle HTTP requests/responses
‚îú‚îÄ Validation (Pydantic)
‚îî‚îÄ Error formatting

Service Layer (qwen_service.py)
‚îú‚îÄ Business logic
‚îú‚îÄ External API calls
‚îî‚îÄ Data transformation
```

### 2. **Type Hints**

```python
async def generate_response(
    self,
    message: str,           # Type hint
    temperature: Optional[float] = None,
    ...
) -> Dict[str, Any]:        # Return type
```

**Benefits:**

- Better IDE autocomplete
- Type checking
- Self-documenting code

### 3. **Dependency Injection**

```python
# Service instance created once
qwen_service = QwenService()

# Router imports and uses it
from app.services.qwen_service import qwen_service

@router.post("/chat")
async def chat(...):
    result = await qwen_service.generate_response(...)
```

### 4. **Configuration Management**

```python
# Don't hardcode!
# ‚ùå Bad
base_url = "http://localhost:8000"

# ‚úÖ Good
base_url = settings.QWEN_BASE_URL
```

### 5. **Comprehensive Comments**

```python
"""
Docstring explains:
- What the function does
- Args with types and descriptions
- Returns with format
- Examples
"""

# Inline comments explain WHY
# Not WHAT (code should be self-explanatory)
```

---

## üîç Debugging Tips

### 1. **Check Logs**

```python
print(f"[Qwen] Received: {message}")
print(f"[Qwen] Response: {result}")
```

### 2. **Test Endpoints Individually**

```bash
# Test vLLM directly
curl http://localhost:8000/v1/models

# Test FastAPI health
curl http://localhost:8000/qwen/health

# Test chat
curl -X POST http://localhost:8000/qwen/chat -d '{"message":"Hi"}'
```

### 3. **Use API Docs**

Open http://localhost:8000/docs

- Try endpoints interactively
- See request/response schemas
- Check error messages

### 4. **Monitor Resource Usage**

```powershell
# Check CPU/Memory
Get-Process python

# Check network
netstat -ano | findstr :8000
```

---

## üéØ Next Steps

B√¢y gi·ªù b·∫°n ƒë√£ c√≥:
‚úÖ Gemini (cloud) cho production quality
‚úÖ Qwen3 (local) cho learning v√† experiments

**Ti·∫øp theo:**

1. Test c·∫£ 2 models v√† compare
2. H·ªçc v·ªÅ embeddings v√† vector databases
3. Implement RAG v·ªõi Qwen3
4. Add LangChain cho advanced workflows

**Happy learning!** üöÄ
